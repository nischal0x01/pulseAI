{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5451a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8175ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for systolic blood pressure only\n",
    "def build_dataset_SBPLabel(Path, FieldName=\"Subsets\"):\n",
    "    data = loadmat(Path, squeeze_me=True, struct_as_record=False)\n",
    "    subset = data[FieldName]\n",
    "\n",
    "    # extracting fields\n",
    "    Signals = subset.Signals            # shape: (N, signal_length)\n",
    "    SBPLabels = subset.SBP              # shape: (N,)\n",
    "    Age = subset.Age\n",
    "    Gender = subset.Gender              # ['M', 'F', ...]\n",
    "    Height = subset.Height\n",
    "    Weight = subset.Weight\n",
    "\n",
    "    # convert Gender into numeric: male=1, female=0\n",
    "    Gender = np.array([1.0 if g == 'M' else 0.0 for g in Gender])\n",
    "\n",
    "    # combine demographic info\n",
    "    Demographics = np.column_stack([Age, Gender, Height, Weight])\n",
    "\n",
    "    return Signals, SBPLabels, Demographics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65142dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for diastolic blood pressure only\n",
    "def build_dataset_DBPLabel(Path, FieldName=\"Subsets\"):\n",
    "    data = loadmat(Path, squeeze_me=True, struct_as_record=False)\n",
    "    subset = data[FieldName]\n",
    "\n",
    "    # extracting fields\n",
    "    Signals = subset.Signals            # shape: (N, signal_length)\n",
    "    DBPLabels = subset.DBP              \n",
    "    Age = subset.Age\n",
    "    Gender = subset.Gender              # ['M', 'F', ...]\n",
    "    Height = subset.Height\n",
    "    Weight = subset.Weight\n",
    "\n",
    "    # convert Gender into numeric: male=1, female=0\n",
    "    Gender = np.array([1.0 if g == 'M' else 0.0 for g in Gender])\n",
    "\n",
    "    # combine demographic info\n",
    "    Demographics = np.column_stack([Age, Gender, Height, Weight])\n",
    "\n",
    "    return Signals, DBPLabels, Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996328f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate the datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Check if processed data directory exists and has MATLAB files\n",
    "processed_dir = '../data/processed'\n",
    "if not os.path.exists(processed_dir) or not os.listdir(processed_dir):\n",
    "    print(\"‚ùå No processed data found. Please:\")\n",
    "    print(\"1. Run the data loader script to download PulseDB dataset\")\n",
    "    print(\"2. Place processed .mat files in data/processed/\")\n",
    "else:\n",
    "    # Try to load data files\n",
    "    mat_files = [f for f in os.listdir(processed_dir) if f.endswith('.mat')]\n",
    "    print(f\"üìÅ Found {len(mat_files)} MATLAB files: {mat_files}\")\n",
    "    \n",
    "    if mat_files:\n",
    "        # Process the first file as example\n",
    "        file_path = os.path.join(processed_dir, mat_files[0])\n",
    "        print(f\"\\nüîÑ Processing: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load SBP dataset\n",
    "            signals_sbp, sbp_labels, demographics_sbp = build_dataset_SBPLabel(file_path)\n",
    "            print(f\"‚úÖ SBP Dataset loaded:\")\n",
    "            print(f\"   - Signals shape: {signals_sbp.shape}\")\n",
    "            print(f\"   - SBP labels shape: {sbp_labels.shape}\")\n",
    "            print(f\"   - Demographics shape: {demographics_sbp.shape}\")\n",
    "            print(f\"   - SBP range: {sbp_labels.min():.1f} - {sbp_labels.max():.1f} mmHg\")\n",
    "            \n",
    "            # Load DBP dataset  \n",
    "            signals_dbp, dbp_labels, demographics_dbp = build_dataset_DBPLabel(file_path)\n",
    "            print(f\"‚úÖ DBP Dataset loaded:\")\n",
    "            print(f\"   - Signals shape: {signals_dbp.shape}\")\n",
    "            print(f\"   - DBP labels shape: {dbp_labels.shape}\")\n",
    "            print(f\"   - Demographics shape: {demographics_dbp.shape}\")\n",
    "            print(f\"   - DBP range: {dbp_labels.min():.1f} - {dbp_labels.max():.1f} mmHg\")\n",
    "            \n",
    "            # Save processed data as numpy arrays for faster loading\n",
    "            np.save(os.path.join(processed_dir, 'signals_sbp.npy'), signals_sbp)\n",
    "            np.save(os.path.join(processed_dir, 'sbp_labels.npy'), sbp_labels)\n",
    "            np.save(os.path.join(processed_dir, 'demographics_sbp.npy'), demographics_sbp)\n",
    "            \n",
    "            np.save(os.path.join(processed_dir, 'signals_dbp.npy'), signals_dbp)\n",
    "            np.save(os.path.join(processed_dir, 'dbp_labels.npy'), dbp_labels)\n",
    "            np.save(os.path.join(processed_dir, 'demographics_dbp.npy'), demographics_dbp)\n",
    "            \n",
    "            print(f\"\\nüíæ Processed data saved as .npy files for faster loading\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing data: {e}\")\n",
    "            print(\"Please check your MATLAB file structure and field names\")\n",
    "    else:\n",
    "        print(\"‚ùå No .mat files found in processed directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
